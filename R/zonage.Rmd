---
title: "Zonage des décisions"
author: "Michaël Benesty"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

Pour cet exercice, il n'y a pas eu de recherche des hyperparamètres qui pourraient être améliorés.  
L'approche choisie est une classification multiclass avec `fastrtext`.  
La prédiction du type du paragraphe est séparée de la prédiction de la partie concernée.

# Pré traitements

## Chargement des librairies

```{R lib_loading}
library(data.table)
library(DT)
library(fastrtext)
library(stringi)
library(assertthat)
library(ggplot2)
set.seed(123)
``` 

## Lecture des données

```{R read_data}
dt <- fread(input = "./annotations-clean.csv", encoding = "UTF-8")
print(head(dt))

```

Il y a **`r nrow(dt)`** paragraphes dans le jeu de données.

## Comptage des types

Ce comptage est fait avant le retrait de certaines catégories et/ou compression de plusieurs types en 1.

```{R display_raw_types}
datatable(dt[, .(nb_mots = round(mean(stri_count_words(text))), nb_doc = .N), types][, `%` := round(100 * nb_doc / sum(nb_doc), 2)])
```

## Retrait de certaines catégories

Certains types sont regroupés, les paragraphes typés `n_a` sont retirés.

```{R simplify_tags}
# remove paragraph type position
dt[, types_clean := stri_replace_all_regex(types, "-\\d+", "")]

# remove double labels due to numbers
make_unique_labels <- function(label) {
  paste(sort(unique(unlist(stri_split_fixed(label, pattern = " ")))), collapse = " ")
}

dt[, types_clean := sapply(types_clean, make_unique_labels)]

# rationalizing motifs and dispositifs
dt[, types_clean := ifelse(stri_detect_regex(types_clean, "^Motif"), ifelse(stri_detect_fixed(types_clean, "Motif_texte"), "Motif_texte", "Motif"), types_clean)]
dt[types_clean == "Dispositif-demandes_accessoires", types_clean := "Dispositif_demandes_accessoires"]
dt[types_clean == "Dispositif Dispositif-demandes_accessoires", types_clean := "Dispositif_demandes_accessoires"]
dt[types_clean == "Contenu_decision_attaquee Expose_litige", types_clean := "Contenu_decision_attaquee_Expose_litige"]
dt[types_clean == "Entete_appelant Entete_avocat", types_clean := "Entete_appelant_avec_avocat"]
dt[types_clean == "Entete_avocat Entete_intime", types_clean := "Entete_intime_avec_avocat"]
dt[, types_clean := stri_replace_all_regex(types_clean, "_intime|_appelant", "")]

dt[, position := as.numeric(seq(types_clean)) / length(types_clean), file]

dt[, intime := stri_detect_fixed(types, "_intime")]
dt[, appelant := stri_detect_fixed(types, "_appelant")]

# check that no paragraph are related to both types.
stopifnot(dt[, sum(intime & appelant)] == 0)

dt[, side := ifelse(intime | appelant, ifelse(appelant, "appelant", "intime"), "aucun")]

dt_cleaned <- dt[types_clean != "n_a"]
```

## Préparation des données

La transformation des paragraphes pour l'apprentissage consiste essentiellement à ajouter les paragraphes qui précèdent et suivent sous forme de contexte.

```{R text_preprocessing}
add_prefix <- function(labels, prefix) {
  add_prefix_item <- function(label, prefix) {
    s <- stri_extract_all_boundaries(label, simplify = TRUE)
    paste0(prefix, s, collapse = " ")
  }
  
  sapply(labels, FUN = add_prefix_item, prefix = prefix, USE.NAMES = FALSE)
}

swipe_features <- function(file, text, nbr) {
  if (nbr > 0) {
    p <- paste0("previous_", nbr, "_")
    r <- add_prefix(c(rep("", nbr), head(text, -nbr)), p)
    f <- c(rep("", nbr), head(file, -nbr)) == file
    ifelse(f, r, "")
  } else {
    nbr <- abs(nbr)
    p <- paste0("next_", nbr, "_")
    r <- add_prefix(c(tail(text, -nbr), rep("", nbr)), p)
    f <- c(tail(file, -nbr), rep("", nbr)) == file
    ifelse(f, r, "")
  }
}

dt_cleaned[, text := stri_replace_all_regex(tolower(text), pattern = "[:punct:]", replacement = " ")]
dt_cleaned[, features_without_label := paste(swipe_features(file, text, 3), swipe_features(file, text, 2), swipe_features(file, text, 1), text, swipe_features(file, text, -1), swipe_features(file, text, -2), swipe_features(file, text, -3))]

train_rows <- seq(0.8 * nrow(dt_cleaned))
test_rows <- seq(max(train_rows) + 1, nrow(dt_cleaned))

```

# Apprentissages

## Typage des paragraphes

On essaye ci-dessous de deviner la nature du paragraphe.

```{R paragraph_types_learning}

local({
  dt_cleaned[, features_with_type_label := paste(add_prefix(types_clean, "__label__"), features_without_label)]
  temp_file_train <- tempfile()
  temp_file_model <- tempfile()
  writeLines(dt_cleaned[train_rows, sample(features_with_type_label)], con = temp_file_train)
  execute(commands = c("supervised", "-input", temp_file_train, "-output", temp_file_model, "-dim", 10, "-lr", 1, "-epoch", 20, "-wordNgrams", 3, "-verbose", 0))
  model <- load_model(temp_file_model)
  predictions <- predict(model, sentences = dt_cleaned[test_rows][, features_with_type_label], simplify = TRUE)
  predicted_labels <- names(predictions)
  invisible(assert_that(length(test_rows) == length(predicted_labels)))
  dt_cleaned[test_rows, predicted_labels := predicted_labels]
  datatable(dt_cleaned[test_rows, .(nb_mots = round(mean(stri_count_words(text))), nb_doc = .N, accuracy = round(100 * mean(predicted_labels == types_clean), 2)), types_clean])
})
```

En moyenne, le bon type est trouvé dans **`r round(100 * dt_cleaned[test_rows, mean(predicted_labels == types_clean)], 2)`%** des **`r length(test_rows)`** paragraphes.

## Typage macro

Des tags macro sont présents dans le fichier.

```{R paragraph_types_macro_learning}

local({
  dt_cleaned[, features_with_type_macro := paste(add_prefix(types_macro, "__label__"), features_without_label)]
  temp_file_train <- tempfile()
  temp_file_model <- tempfile()
  writeLines(dt_cleaned[train_rows, sample(features_with_type_macro)], con = temp_file_train)
  execute(commands = c("supervised", "-input", temp_file_train, "-output", temp_file_model, "-dim", 10, "-lr", 1, "-epoch", 20, "-wordNgrams", 3, "-verbose", 0))
  model <- load_model(temp_file_model)
  predictions <- predict(model, sentences = dt_cleaned[test_rows, features_with_type_macro], simplify = TRUE)
  invisible(assert_that(length(test_rows) == length(predictions)))
  dt_cleaned[test_rows, predicted_labels_macro := names(predictions)]
  datatable(dt_cleaned[test_rows, .(nb_mots = round(mean(stri_count_words(text))), nb_doc = .N, accuracy = round(100 * mean(types_macro == predicted_labels_macro), 2)), types_macro])
})

```

En moyenne, le bon type macro est trouvé dans **`r round(100 * dt_cleaned[test_rows, mean(predicted_labels_macro == types_macro)], 2)`%** des **`r length(test_rows)`** paragraphes.

## Partie concernée par un paragraphe

On essaye de prédire qui est lié au paragraphe.

```{R paragraph_side_learning}
local({
  dt_cleaned[, features_with_side_label := paste(add_prefix(side, "__label__"), features_without_label)]
  temp_file_train <- tempfile()
  temp_file_model <- tempfile()
  writeLines(dt_cleaned[train_rows, sample(features_with_side_label)], con = temp_file_train)
  execute(commands = c("supervised", "-input", temp_file_train, "-output", temp_file_model, "-dim", 10, "-lr", 1, "-epoch", 20, "-wordNgrams", 3, "-verbose", 0))
  model <- load_model(temp_file_model)
  predictions <- predict(model, sentences = dt_cleaned[test_rows, features_with_side_label], simplify = TRUE)
  invisible(assert_that(length(test_rows) == length(predictions)))
  dt_cleaned[test_rows, predicted_side := names(predictions)]
  datatable(dt_cleaned[test_rows, .(nb_mots = round(mean(stri_count_words(text))), nb_doc = .N, accuracy = round(100 * mean(predicted_side == side), 2)), side])
})
```

En moyenne, la partie concernée par un paragraphe est trouvée dans **`r round(100 * dt_cleaned[test_rows, mean(predicted_side == side)], 2)`%** des **`r length(test_rows)`** paragraphes.
