---
title: "Zonage des décisions"
author: "Michaël Benesty"
date: "5 novembre 2017"
output: html_document
---

## Chargement des librairies

```{R}
library(data.table)
library(DT)
library(fastrtext)
library(stringi)
library(assertthat)
library(ggplot2)
set.seed(123)
``` 

## Lecture des données

```{R}
dt <- fread(input = "./annotations-20-lots.csv", encoding = "UTF-8")
print(head(dt))

```

Il y a **`r nrow(dt)`** paragraphes typés.

## Comptage des types

Avant retrait de certaines catégories

```{R}
datatable(dt[, .(nb_mots = round(mean(stri_count_words(text))), nb_doc = .N), types][, `%` := round(100 * nb_doc / sum(nb_doc), 2)])
```

## Retrait de certaines catégories

Les types sont groupés.

Sont retirés :

* les documents de moins de 35 lignes
* la catégorie `n_a`
* les paragraphes qui ont moins de 4 mots
* les catégories qui ont une fréquence de moins de 20

```{R}
under_35_lines <- dt[, .N, filename][N <= 35, filename]
# remove paragraph position
dt[, types := stri_replace_all_regex(types, "-\\d+", "")]
types_to_remove <- dt[stri_count_words(str = text) > 3][, .N, types][N < 20, types]
dt_cleaned <- dt[!types %in% c(types_to_remove, "n_a")][!filename %in% under_35_lines][stri_count_words(str = text) > 3]
```

## Construction d'un modèle pour fastrtext

```{R}
dt_sampled <- dt_cleaned[sample(nrow(dt_cleaned))]
add_prefix_item <- function(label, prefix) {
  s <- stri_extract_all_boundaries(label, simplify = TRUE)
  paste0(prefix, s, collapse = " ")
}

add_prefix <- function(labels, prefix) sapply(labels, FUN = add_prefix_item, prefix = prefix, USE.NAMES = FALSE)
dt_sampled[, text := tolower(text)]
dt_sampled[, previous_text := add_prefix(c("", head(text, -1)), "previous_")]
dt_sampled[, next_text := add_prefix(c(tail(text, -1), ""), "next_")]


dt_sampled[, features := paste(add_prefix(types, "__label__"), text)]
temp_file_train <- tempfile()
temp_file_model <- tempfile()

invisible(assert_that(nrow(dt_sampled) > 8000))
train_rows <- seq(8000)
test_rows <- seq(max(train_rows) + 1, nrow(dt_sampled))

writeLines(dt_sampled[train_rows, features], con = temp_file_train)

execute(commands = c("supervised", "-input", temp_file_train, "-output", temp_file_model, "-dim", 20, "-lr", 1, "-epoch", 200, "-wordNgrams", 3, "-verbose", 0))

dt_sampled_with_predictions <- dt_sampled[test_rows]
model <- load_model(temp_file_model)
predictions <- predict(model, sentences = dt_sampled_with_predictions[, features], simplify = TRUE)

predicted_labels <- names(predictions)
invisible(assert_that(length(test_rows) == length(predicted_labels)))

dt_sampled_with_predictions[,predicted_labels := predicted_labels]

datatable(dt_sampled_with_predictions[, .(nb_mots = round(mean(stri_count_words(text))), nb_doc = .N, accuracy = round(100 * mean(predicted_labels == types), 2)), types])

```

En moyenne, le bon type est trouvé dans **`r round(100 * dt_sampled_with_predictions[, mean(predicted_labels == types)], 2)`%** des cas et représente **`r nrow(dt_sampled_with_predictions)`** paragraphes.
