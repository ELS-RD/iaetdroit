---
title: "Zonage des décisions"
author: "Michaël Benesty"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

Pour cet exercice, il n'y a pas eu de recherche des hyper-paramètres qui pourraient être améliorés.  
L'approche choisie est une classification multiclass avec `fastrtext`.  
Les prédiction des types de chaque paragraphe (micro et macro) sont séparées de la prédiction de la partie concernée.

# Pré-traitements

## Chargement des librairies

```{R lib_loading}
library(data.table)
library(DT)
library(fastrtext)
library(stringi)
library(assertthat)
library(ggplot2)
set.seed(123)
``` 

## Lecture des données

```{R read_data}
dt <- fread(input = "./annotations-clean.csv", encoding = "UTF-8")
print(head(dt))

```

Il y a **`r nrow(dt)`** paragraphes dans le jeu de données.

## Comptage des types

Ce comptage est fait avant le retrait de certaines catégories et/ou compression de plusieurs types en 1.  
Il s'agit de donner un aperçu de la répartition des données brutes.

```{R display_raw_types}
datatable(dt[, .(nb_mots_moyen = round(mean(stri_count_words(text))), nb_decisions = .N), types][, `%` := round(100 * nb_decisions / sum(nb_decisions), 2)])
```

## Répartition des difficultés

Les annotateurs ont noté la difficulté d'annoter chaque décision.

```{R difficulties}
datatable(dt[, .(nb_paragraphes = .N), annotation_difficulty][, `%` := round(100 * nb_paragraphes / sum(nb_paragraphes), 2)])
```

Les décisions jugées difficiles à annoter sont conservées dans le jeu de données.  
Le retrait de ces décisions ne change pas de façon significative les résultats.

## Retrait de certaines catégories

Certains types sont regroupés.  
Les paragraphes typés `n_a` sont conservés.

```{R simplify_tags}
# remove paragraph type position
dt[, types_clean_micro := stri_replace_all_regex(types, "-\\d+", "")]

# remove double labels due to numbers
make_unique_labels <- function(label) {
  paste(sort(unique(unlist(stri_split_fixed(label, pattern = " ")))), collapse = " ")
}

dt[, types_clean_micro := sapply(types_clean_micro, make_unique_labels)]

# rationalizing motifs and dispositifs
dt[, types_clean_micro := ifelse(stri_detect_regex(types_clean_micro, "^Motif"), ifelse(stri_detect_fixed(types_clean_micro, "Motif_texte"), "Motif_texte", "Motif"), types_clean_micro)]
dt[types_clean_micro == "Dispositif-demandes_accessoires", types_clean_micro := "Dispositif_demandes_accessoires"]
dt[types_clean_micro == "Dispositif Dispositif-demandes_accessoires", types_clean_micro := "Dispositif_demandes_accessoires"]
dt[types_clean_micro == "Contenu_decision_attaquee Expose_litige", types_clean_micro := "Contenu_decision_attaquee_Expose_litige"]
dt[types_clean_micro == "Entete_appelant Entete_avocat", types_clean_micro := "Entete_appelant_avec_avocat"]
dt[types_clean_micro == "Entete_avocat Entete_intime", types_clean_micro := "Entete_intime_avec_avocat"]
dt[, types_clean_micro := stri_replace_all_regex(types_clean_micro, "_intime|_appelant", "")]

dt[, position := as.numeric(seq(types_clean_micro)) / length(types_clean_micro), file]

dt[, intime := stri_detect_fixed(types, "_intime")]
dt[, appelant := stri_detect_fixed(types, "_appelant")]

# check that no paragraph are related to both types.
stopifnot(dt[, sum(intime & appelant)] == 0)

dt[, side := ifelse(intime | appelant, ifelse(appelant, "appelant", "intime"), "aucun")]
```

## Préparation des données

La transformation des paragraphes pour l'apprentissage consiste essentiellement à ajouter les paragraphes qui précèdent et suivent sous forme de contexte.  
Présentement, les 3 paragraphes précédents et suivant sont ajoutés. Pour permettre au modèle de les distinguer du paragraphe à prédire, un préfixe est ajouté à chaque mot du contexte. Cette méthode augmente les résultats de plus de 10 points en fonction des tâches.

```{R text_preprocessing}
add_prefix <- function(prefix, labels) {
  add_prefix_item <- function(label, prefix) {
    s <- stri_extract_all_boundaries(label, simplify = TRUE)
    paste0(prefix, s, collapse = " ")
  }
  
  sapply(labels, FUN = add_prefix_item, prefix = prefix, USE.NAMES = FALSE)
}

swipe_features <- function(file, text, nbr) {
  if (nbr > 0) {
    p <- paste0("previous_", nbr, "_")
    r <- add_prefix(p, c(rep("", nbr), head(text, -nbr)))
    f <- c(rep("", nbr), head(file, -nbr)) == file
    ifelse(f, r, "")
  } else {
    nbr <- abs(nbr)
    p <- paste0("next_", nbr, "_")
    r <- add_prefix(p, c(tail(text, -nbr), rep("", nbr)))
    f <- c(tail(file, -nbr), rep("", nbr)) == file
    ifelse(f, r, "")
  }
}

dt[, text := stri_replace_all_regex(tolower(text), pattern = "[:punct:]", replacement = " ")]
dt[, features_without_label := paste(swipe_features(file, text, 3), swipe_features(file, text, 2), swipe_features(file, text, 1), text, swipe_features(file, text, -1), swipe_features(file, text, -2), swipe_features(file, text, -3))]

train_rows <- seq(0.8 * nrow(dt))
test_rows <- seq(max(train_rows) + 1, nrow(dt))
```

### Affichage d'un exemple de paragraphe.

```{R example}
# Original text, paragraphs 1 to 7
print(dt[1:7, text])

# Paragraph 4 with its context (as seen by fastrtext)
print(dt[4, features_without_label])
```

# Apprentissages

## Typage des paragraphes

On essaye ci-dessous de deviner la nature du paragraphe.

```{R paragraph_types_learning}

local({
  dt[, features_with_type_label := paste(add_prefix("__label__", types_clean_micro), features_without_label)]
  temp_file_train <- tempfile()
  temp_file_model <- tempfile()
  writeLines(dt[train_rows, sample(features_with_type_label)], con = temp_file_train)
  execute(commands = c("supervised", "-input", temp_file_train, "-output", temp_file_model, "-dim", 10, "-lr", 1, "-epoch", 20, "-wordNgrams", 2, "-verbose", 0))
  model <- load_model(temp_file_model)
  predictions <- predict(model, sentences = dt[test_rows][, features_with_type_label], simplify = TRUE)
  predicted_labels <- names(predictions)
  invisible(assert_that(length(test_rows) == length(predicted_labels)))
  dt[test_rows, predicted_labels := predicted_labels]
  datatable(dt[test_rows, .(nb_mots_moyen = round(mean(stri_count_words(text))), nb_decisions = .N, accuracy = round(100 * mean(predicted_labels == types_clean_micro), 2)), types_clean_micro])
})
```

En moyenne, le bon type est trouvé dans **`r round(100 * dt[test_rows, mean(predicted_labels == types_clean_micro)], 2)`%** des **`r length(test_rows)`** paragraphes.

## Typage macro

Des tags macro sont présents dans le fichier.

```{R paragraph_types_macro_learning}

local({
  dt[, features_with_type_macro := paste(add_prefix("__label__", types_macro), features_without_label)]
  temp_file_train <- tempfile()
  temp_file_model <- tempfile()
  writeLines(dt[train_rows, sample(features_with_type_macro)], con = temp_file_train)
  execute(commands = c("supervised", "-input", temp_file_train, "-output", temp_file_model, "-dim", 10, "-lr", 1, "-epoch", 20, "-wordNgrams", 2, "-verbose", 0))
  model <- load_model(temp_file_model)
  predictions <- predict(model, sentences = dt[test_rows, features_with_type_macro], simplify = TRUE)
  invisible(assert_that(length(test_rows) == length(predictions)))
  dt[test_rows, predicted_labels_macro := names(predictions)]
  datatable(dt[test_rows, .(nb_mots_moyen = round(mean(stri_count_words(text))), nb_decisions = .N, accuracy = round(100 * mean(types_macro == predicted_labels_macro), 2)), types_macro])
})

```

En moyenne, le bon type macro est trouvé dans **`r round(100 * dt[test_rows, mean(predicted_labels_macro == types_macro)], 2)`%** des **`r length(test_rows)`** paragraphes.

## Partie concernée par un paragraphe

On essaye de prédire qui est lié au paragraphe.

```{R paragraph_side_learning}
local({
  dt[, features_with_side_label := paste(add_prefix("__label__", side), features_without_label)]
  temp_file_train <- tempfile()
  temp_file_model <- tempfile()
  writeLines(dt[train_rows, sample(features_with_side_label)], con = temp_file_train)
  execute(commands = c("supervised", "-input", temp_file_train, "-output", temp_file_model, "-dim", 10, "-lr", 1, "-epoch", 20, "-wordNgrams", 2, "-verbose", 0))
  model <- load_model(temp_file_model)
  predictions <- predict(model, sentences = dt[test_rows, features_with_side_label], simplify = TRUE)
  invisible(assert_that(length(test_rows) == length(predictions)))
  dt[test_rows, predicted_side := names(predictions)]
  datatable(dt[test_rows, .(nb_mots_moyen = round(mean(stri_count_words(text))), nb_decisions = .N, accuracy = round(100 * mean(predicted_side == side), 2)), side])
})
```

En moyenne, la partie concernée par un paragraphe est trouvée dans **`r round(100 * dt[test_rows, mean(predicted_side == side)], 2)`%** des **`r length(test_rows)`** paragraphes.
